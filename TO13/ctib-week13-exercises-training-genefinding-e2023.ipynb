{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math  # Just ignore this :-)\n",
    "\n",
    "def log(x):\n",
    "    if x == 0:\n",
    "        return float('-inf')\n",
    "    return math.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTiB E2023 - Week 13 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical exercises\n",
    "\n",
    "***Exercise 1***: Consider the simple \"weather-HMM\" with a transition diagram as shown on slide 3 in the slides *Hidden Markov Models - Training - Selecting model parameter* from the lecture on Nov 27. Assume that we do not know the model parameters i.e. the start-, transition-, and emission-probabilities, but that we are given two pairs of $({\\bf X}, {\\bf Z})$ as training data. \n",
    "\n",
    "These pairs are: (`HHLLLHHHHLLLLHH`, `SSSRRSSSRRRRSSS`) and (`LLHHLLLHHHHLLHH`, `RRRSSRRRSSSRRRS`), where H and L are the two states of the model, and S and R are the two emissions sunshine and rain.  \n",
    "\n",
    "Use Training-by-Counting to set the model parameters according to this training data.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tabel](tabel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Exercise 2***: Consider the 7-state HMM on slides 26 in slides *Hidden Markov Models - Selecting the initial model parameters and using HMMs for (simpel) gene finding* from the lecture on Nov 27, which you will use in pratical exercises below. As stated on slide 27, this HMM is also relevant for gene finding, where we say that state 3 emits non-coding symbols, states 2, 1, 0 emit coding triplets (codons) in the left-to-right direction and states 4, 5, 6 emit coding symbols in the reverse (right-to-left) direction. \n",
    "\n",
    "If we are given a DNA string, say \n",
    "\n",
    "`ACGTATGCTAATCTAAACCTACGGCATGT`\n",
    "\n",
    "and information about its gene structure using the N, C, R annotation also used in the slides and practical exercises, say   \n",
    "\n",
    "`NNNNCCCCCCCCCCCCNNRRRRRRRRRNN`    \n",
    "\n",
    "then we can convert this gene structure into an actual sequence of states, as also explained on slide 30 (for a different model), as\n",
    "\n",
    "`33332102102102103345645645633`\n",
    "\n",
    "Use the above DNA string and information about its gene structure to set the model parameters of the 7-state HMM using Traning-by-Counting. (You can perhaps use this small example as a test case for your implementation of Traning-by-Counting in the practical exercises.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 1, 4]\n",
      "[[0.375, 0.25, 0.25, 0.125], [0.25, 0.125, 0.125, 0.5], [0.375, 0.25, 0.125, 0.25], [0.25, 0.25, 0.25, 0.25], [0.14285714285714285, 0.5714285714285714, 0.14285714285714285, 0.14285714285714285], [0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857], [0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857]]\n",
      "[[0.09090909090909091, 0.09090909090909091, 0.36363636363636365, 0.18181818181818182, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091], [0.45454545454545453, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091], [0.09090909090909091, 0.45454545454545453, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091], [0.07142857142857142, 0.07142857142857142, 0.14285714285714285, 0.42857142857142855, 0.14285714285714285, 0.07142857142857142, 0.07142857142857142], [0.1, 0.1, 0.1, 0.1, 0.1, 0.4, 0.1], [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.4], [0.1, 0.1, 0.1, 0.2, 0.3, 0.1, 0.1]]\n",
      "[0.125, 0.125, 0.125, 0.25, 0.125, 0.125, 0.125]\n"
     ]
    }
   ],
   "source": [
    "DNA_string ='ACGTATGCTAATCTAAACCTACGGCATGT' #observable\n",
    "hidden_path='33332102102102103345645645633' #hidden states\n",
    "\n",
    "def translate_observations_to_indices(obs):\n",
    "    mapping = {'a': 0, 'c': 1, 'g': 2, 't': 3}\n",
    "    return [mapping[symbol.lower()] for symbol in obs]\n",
    "\n",
    "DNA_string_index = translate_observations_to_indices(DNA_string)\n",
    "\n",
    "k = 7 #antallet af hidden states\n",
    "d = 4 #antallet af observable states\n",
    "\n",
    "#initial_list=[1]*k\n",
    "#emission_list=[[1]*d]*k\n",
    "#transition_list=[[1]*k]*k\n",
    "\n",
    "initial_list = [1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "transition_list = [\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1]\n",
    "]\n",
    "\n",
    "emission_list = [\n",
    "    #   A     C     G     T\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1]\n",
    "]\n",
    "\n",
    "#print(emission_list)\n",
    "\n",
    "for i in range(len(DNA_string_index)):\n",
    "    if i == 0:\n",
    "        initial_list[int(hidden_path[i])] += 1\n",
    "        emission_list[int(hidden_path[i])][DNA_string_index[i]] += 1\n",
    "    else:\n",
    "        #print(int(hidden_path[i]),DNA_string_index[i])\n",
    "        emission_list[int(hidden_path[i])][DNA_string_index[i]] += 1\n",
    "        transition_list[int(hidden_path[i-1])][int(hidden_path[i])] +=1\n",
    "\n",
    "print((emission_list[1]))\n",
    "\n",
    "for k in range(len(emission_list)): #rækken\n",
    "    #sum_k = sum(emission_list[k])\n",
    "    sum = 0\n",
    "    for i in range(len(emission_list[0])):\n",
    "        sum += emission_list[k][i]\n",
    "    for d in range(len(emission_list[0])): #kolonnen\n",
    "        new_value = emission_list[k][d]/sum\n",
    "        emission_list[k][d] = new_value\n",
    "\n",
    "for k in range(len(transition_list)): #rækken\n",
    "    sum = 0\n",
    "    for i in range(len(transition_list[0])):\n",
    "        sum += transition_list[k][i]\n",
    "    for d in range(len(transition_list[0])): #kolonnen\n",
    "        new_value = transition_list[k][d]/sum\n",
    "        transition_list[k][d] = new_value\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(initial_list)):\n",
    "    sum += initial_list[i]\n",
    "for k in range(len(initial_list)): #rækker\n",
    "    new_value = initial_list[k]/sum\n",
    "    initial_list[k] = new_value\n",
    "\n",
    "\n",
    "print(emission_list)\n",
    "print(transition_list)\n",
    "print(initial_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical exercises\n",
    "\n",
    "In the exercise below, you will implement and experiment with various ways of training a HMM (i.e. deciding parameters from data), and you will see an example of how to apply a HMM for identifying coding regions (genes) in genetic matrial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given the same 7-state HMM and helper functions that you used last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class hmm:\n",
    "    def __init__(self, init_probs, trans_probs, emission_probs):\n",
    "        self.init_probs = init_probs\n",
    "        self.trans_probs = trans_probs\n",
    "        self.emission_probs = emission_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_probs_7_state = [0.00, 0.00, 0.00, 1.00, 0.00, 0.00, 0.00]\n",
    "\n",
    "trans_probs_7_state = [\n",
    "    [0.00, 0.00, 0.90, 0.10, 0.00, 0.00, 0.00],\n",
    "    [1.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 1.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.05, 0.90, 0.05, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 1.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.00],\n",
    "    [0.00, 0.00, 0.00, 0.10, 0.90, 0.00, 0.00],\n",
    "]\n",
    "\n",
    "emission_probs_7_state = [\n",
    "    #   A     C     G     T\n",
    "    [0.30, 0.25, 0.25, 0.20],\n",
    "    [0.20, 0.35, 0.15, 0.30],\n",
    "    [0.40, 0.15, 0.20, 0.25],\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.20, 0.40, 0.30, 0.10],\n",
    "    [0.30, 0.20, 0.30, 0.20],\n",
    "    [0.15, 0.30, 0.20, 0.35],\n",
    "]\n",
    "\n",
    "hmm_7_state = hmm(init_probs_7_state, trans_probs_7_state, emission_probs_7_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_observations_to_indices(obs):\n",
    "    mapping = {'a': 0, 'c': 1, 'g': 2, 't': 3}\n",
    "    return [mapping[symbol.lower()] for symbol in obs]\n",
    "\n",
    "def translate_indices_to_observations(indices):\n",
    "    mapping = ['a', 'c', 'g', 't']\n",
    "    return ''.join(mapping[idx] for idx in indices)\n",
    "\n",
    "def translate_path_to_indices(path):\n",
    "    return list(map(lambda x: int(x), path))\n",
    "\n",
    "def translate_indices_to_path(indices):\n",
    "    return ''.join([str(i) for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(m, n):\n",
    "    \"\"\"Make a table with `m` rows and `n` columns filled with zeros.\"\"\"\n",
    "    return [[0] * n for _ in range(m)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training by counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a hidden Markov model is a matter of estimating the initial, transition and emission probabilities. If we are given training data, i.e. a sequence of observations, ${\\bf X}$, and a corresponding sequence of hidden states, ${\\bf Z}$, we can do \"training by counting\" by counting the number of observed transitions and emissions in the training data as explained in the lecture.\n",
    "\n",
    "Given ${\\bf X}$ and ${\\bf Z}$ we would like to count the number of transitions from one state to another, and the number of times that symbol $k$ was observed while being in state $i$.  That is, we want to construct a $K \\times K$ matrix such that entry $i, j$ is the number of times that a transition from state $i$ to state $j$ is observed in the training data, and a $K \\times D$ matrix where entry $i, k$ contains the number of times that symbol $k$ is observed in the training data while being in state $i$.\n",
    "\n",
    "Implement this as the below function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_transitions_and_emissions(K, D, x, z):\n",
    "    \"\"\"\n",
    "    Returns a KxK matrix and a KxD matrix containing counts cf. above\n",
    "    \"\"\"\n",
    "    transition_list = []\n",
    "    emission_list = []\n",
    "    initial_list = []\n",
    "\n",
    "    x = translate_observations_to_indices(x)\n",
    "    z = translate_path_to_indices(z)\n",
    "\n",
    "    for k in range(K):\n",
    "        initial_list.append(1)\n",
    "    \n",
    "    for k1 in range(K):\n",
    "        transition_list.append([])\n",
    "        for k2 in range(K):\n",
    "            transition_list[k1].append(1)\n",
    "\n",
    "    for k in range(K):\n",
    "        emission_list.append([])\n",
    "        for d in range(D):\n",
    "            emission_list[k].append(1)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        if i == 0:\n",
    "            emission_list[z[i]][x[i]] += 1\n",
    "            initial_list[z[i]] += 1\n",
    "        else:\n",
    "            emission_list[z[i]][x[i]] += 1\n",
    "            transition_list[z[i-1]][z[i]] +=1\n",
    "\n",
    "    return initial_list, transition_list, emission_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_long = 'TGAGTATCACTTAGGTCTATGTCTAGTCGTCTTTCGTAATGTTTGGTCTTGTCACCAGTTATCCTATGGCGCTCCGAGTCTGGTTCTCGAAATAAGCATCCCCGCCCAAGTCATGCACCCGTTTGTGTTCTTCGCCGACTTGAGCGACTTAATGAGGATGCCACTCGTCACCATCTTGAACATGCCACCAACGAGGTTGCCGCCGTCCATTATAACTACAACCTAGACAATTTTCGCTTTAGGTCCATTCACTAGGCCGAAATCCGCTGGAGTAAGCACAAAGCTCGTATAGGCAAAACCGACTCCATGAGTCTGCCTCCCGACCATTCCCATCAAAATACGCTATCAATACTAAAAAAATGACGGTTCAGCCTCACCCGGATGCTCGAGACAGCACACGGACATGATAGCGAACGTGACCAGTGTAGTGGCCCAGGGGAACCGCCGCGCCATTTTGTTCATGGCCCCGCTGCCGAATATTTCGATCCCAGCTAGAGTAATGACCTGTAGCTTAAACCCACTTTTGGCCCAAACTAGAGCAACAATCGGAATGGCTGAAGTGAATGCCGGCATGCCCTCAGCTCTAAGCGCCTCGATCGCAGTAATGACCGTCTTAACATTAGCTCTCAACGCTATGCAGTGGCTTTGGTGTCGCTTACTACCAGTTCCGAACGTCTCGGGGGTCTTGATGCAGCGCACCACGATGCCAAGCCACGCTGAATCGGGCAGCCAGCAGGATCGTTACAGTCGAGCCCACGGCAATGCGAGCCGTCACGTTGCCGAATATGCACTGCGGGACTACGGACGCAGGGCCGCCAACCATCTGGTTGACGATAGCCAAACACGGTCCAGAGGTGCCCCATCTCGGTTATTTGGATCGTAATTTTTGTGAAGAACACTGCAAACGCAAGTGGCTTTCCAGACTTTACGACTATGTGCCATCATTTAAGGCTACGACCCGGCTTTTAAGACCCCCACCACTAAATAGAGGTACATCTGA'\n",
    "z_long = '3333321021021021021021021021021021021021021021021021021021021021021021033333333334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210321021021021021021021021033334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563333333456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456332102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102103210210210210210210210210210210210210210210210210210210210210210'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation of `count_transitions_and_emissions` on (prefixes) of `x_long` and `z_long` above in order to conclude that your implementation works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1, 1, 2, 1, 1, 1], [[1, 1, 122, 5, 1, 1, 1], [127, 1, 1, 1, 1, 1, 1], [1, 127, 1, 1, 1, 1, 1], [1, 1, 6, 24, 4, 1, 1], [1, 1, 1, 1, 1, 198, 1], [1, 1, 1, 1, 1, 1, 198], [1, 1, 1, 4, 195, 1, 1]], [[27, 40, 29, 34], [27, 44, 17, 42], [57, 16, 28, 29], [6, 9, 8, 12], [43, 70, 66, 22], [69, 44, 56, 32], [27, 70, 33, 71]])\n"
     ]
    }
   ],
   "source": [
    "print(count_transitions_and_emissions(7, 4, x_long, z_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your implementation of `count_transitions_and_emissions` to implement a function `training_by_counting` that given the number of hidden states, $K$, the number of observables, $D$, a sequence of observations, ${\\bf X}$, and a corresponding sequence of hidden states, ${\\bf Z}$, returns a HMM (as an instance of `class hmm`), where the tranistion, emission, and initial probabilities are set cf. training by counting on ${\\bf X}$ and ${\\bf Z}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_by_counting(K, D, x, z):\n",
    "    \"\"\"\n",
    "    Returns a HMM trained on x and z cf. training-by-counting.\n",
    "    \"\"\"\n",
    "    initial_list, transition_list, emission_list = count_transitions_and_emissions(K, D, x, z)\n",
    "    \n",
    "\n",
    "    for k in range(len(emission_list)): #rækken\n",
    "        sum = 0\n",
    "        for i in range(len(emission_list[0])):\n",
    "            sum += emission_list[k][i]\n",
    "        for d in range(len(emission_list[0])): #kolonnen\n",
    "            new_value = emission_list[k][d]/sum\n",
    "            emission_list[k][d] = new_value\n",
    "\n",
    "    for k in range(len(transition_list)): #rækken\n",
    "        sum = 0\n",
    "        for i in range(len(transition_list[0])):\n",
    "            sum += transition_list[k][i]\n",
    "        for d in range(len(transition_list[0])): #kolonnen\n",
    "            new_value = transition_list[k][d]/sum\n",
    "            transition_list[k][d] = new_value\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(len(initial_list)):\n",
    "        sum += initial_list[i]\n",
    "    for k in range(len(initial_list)): #rækker\n",
    "        new_value = initial_list[k]/sum\n",
    "        initial_list[k] = new_value\n",
    "\n",
    "    model = hmm(initial_list, transition_list, emission_list)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a HMM trained on `x_long` and `z_long`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.hmm object at 0x0000021368D43910>\n"
     ]
    }
   ],
   "source": [
    "hmm_7_state_tbc = training_by_counting(7, 4, x_long, z_long)\n",
    "\n",
    "print(hmm_7_state_tbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this HMM (i.e. its transistion, emission, and initial probabilities) compare to `hmm_7_state` as specified above?\n",
    "\n",
    "You can e.g. try to perform a Viterbi decoding of `x_long` using the two HMMs and investigate if the decodings differ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your implementation of Viterbi (log transformed) from last week\n",
    "\n",
    "def compute_w_log(model, x):\n",
    "    k = len(model.init_probs)\n",
    "    n = len(x)\n",
    "    x = translate_observations_to_indices(x)\n",
    "    \n",
    "    w = make_table(k, n)\n",
    "    \n",
    "    # Base case: fill out w[i][0] for i = 0..k-1\n",
    "    for j in range(k):\n",
    "        ip = model.init_probs[j]\n",
    "        ep = model.emission_probs[j][x[0]]\n",
    "        w[j][0] = log(ip) + log(ep)\n",
    "    \n",
    "    # Inductive case: fill out w[i][j] for i = 0..k, j = 0..n-1\n",
    "    for i in range(1, n):\n",
    "        for j in range(k):\n",
    "            max_prob = float('-inf')\n",
    "            for l in range(k):\n",
    "                tp = model.trans_probs[l][j]\n",
    "                ep = model.emission_probs[j][x[i]]\n",
    "                prob = w[l][i-1] + log(tp) + log(ep)\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "            w[j][i] = max_prob\n",
    "    return w  \n",
    "\n",
    "def opt_path_prob_log(w):\n",
    "    max_prob = float('-inf')\n",
    "    \n",
    "    for j in range(len(w)):\n",
    "        prob = w[j][-1]\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "    return max_prob\n",
    "\n",
    "def backtrack_log(model, x, w):\n",
    "    x = translate_observations_to_indices(x)\n",
    "    \n",
    "    max_prob = float('-inf')\n",
    "    max_prob_position = None \n",
    "    for j in range(len(w)):\n",
    "        prob = w[j][-1]\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            max_prob_position = j\n",
    "    path = str(max_prob_position)\n",
    "\n",
    "    pre_prob = max_prob\n",
    "    pre_prob_position = max_prob_position\n",
    "    \n",
    "    for i in range(-2, -len(x)-1, -1):\n",
    "        for j in range(len(w)):\n",
    "            tp = model.trans_probs[j][pre_prob_position]\n",
    "            ep = model.emission_probs[pre_prob_position][x[i+1]]\n",
    "            prob = w[j][i] + log(tp) + log(ep)\n",
    "            if math.isclose(prob, pre_prob):\n",
    "                pre_prob = w[j][i]\n",
    "                pre_prob_position = j\n",
    "                path = str(j) + path\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333321021021021021021021021021021021021021021021021021021021021021021033333333334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210321021021021021021021021033334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563333333456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456332102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102103210210210210210210210210210210210210210210210210210210210210210\n",
      "1021021021021021021021021021021021021021021021021021021021021021021021021064564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564521021021021021021021021021021021064564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564556456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456452102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102103210210210210210210210210210210210210210210210210210210210210210\n"
     ]
    }
   ],
   "source": [
    "w = compute_w_log(hmm_7_state, x_long)\n",
    "z_vit = backtrack_log(hmm_7_state, x_long, w)\n",
    "\n",
    "w_tbc = compute_w_log(hmm_7_state_tbc, x_long)\n",
    "z_vit_tbc = backtrack_log(hmm_7_state_tbc, x_long, w_tbc)\n",
    "\n",
    "print(z_vit)\n",
    "print(z_vit_tbc)\n",
    "\n",
    "# Your comparison of z_vit and z_vit_tbc here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Using a HMM for Gene Finding\n",
    "\n",
    "Below we will investigate how to use a hidden Markov model for gene finding in prokaryotes.\n",
    "\n",
    "You are give a data set containing 2 Staphylococcus genomes, each containing several genes (i.e. substrings) obeying the \"gene syntax\" explained in class. The genomes are between 1.8 million and 2.8 million nucleotides.\n",
    "\n",
    "The genomes and their annontations are given in [FASTA format](https://en.wikipedia.org/wiki/FASTA_format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(filename):\n",
    "    \"\"\"\n",
    "    Reads the given FASTA file f and returns a dictionary of sequences.\n",
    "\n",
    "    Lines starting with ';' in the FASTA file are ignored.\n",
    "    \"\"\"\n",
    "    sequences_lines = {}\n",
    "    current_sequence_lines = None\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "            if line.startswith(';') or not line:\n",
    "                continue\n",
    "            if line.startswith('>'):\n",
    "                sequence_name = line.lstrip('>')\n",
    "                current_sequence_lines = []\n",
    "                sequences_lines[sequence_name] = current_sequence_lines\n",
    "            else:\n",
    "                if current_sequence_lines is not None:\n",
    "                    current_sequence_lines.append(line)\n",
    "    sequences = {}\n",
    "    for name, lines in sequences_lines.items():\n",
    "        sequences[name] = ''.join(lines)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function like this (note that reading the entire genome will take some time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = read_fasta_file('genome1.fa')\n",
    "g1['genome1'][:50]\n",
    "\n",
    "g2 = read_fasta_file('genome2.fa')\n",
    "\n",
    "z1 = read_fasta_file('true-ann1.fa')\n",
    "z2 = read_fasta_file('true-ann2.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is:\n",
    "\n",
    "* The files [genome1.fa](http://users-birc.au.dk/cstorm/courses/ML_e22/exercises/genome1.fa) and  [genome2.fa](http://users-birc.au.dk/cstorm/courses/ML_e22/exercises/genome2.fa) contain the 2 genomes.\n",
    "* The files [true-ann1.fa](http://users-birc.au.dk/cstorm/courses/ML_e22/exercises/true-ann1.fa) and [true-ann2.fa](http://users-birc.au.dk/cstorm/courses/ML_e22/exercises/true-ann2.fa) contain the annotation of the two genomes with the tru gene structure. The annotation is given in FASTA format as a sequence over the symbols `N`, `C`, and `R`. The symbol `N`, `C`, or `R` at position $i$ in `true-annk.fa` gives the \"state\" of the nucleotide at position $i$ in `genomek.fa`. `N` means that the nucleotide is non-coding. `C` means that the nucleotide is coding and part of a gene in the direction from left to right. `R` means that the nucleotide is coding and part of gene in the reverse direction from right to left.\n",
    "\n",
    "The annotation files can also be read with `read_fasta_file`.\n",
    "\n",
    "You are given the same 7-state HMM that you used above and similar helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class hmm:\n",
    "    def __init__(self, init_probs, trans_probs, emission_probs):\n",
    "        self.init_probs = init_probs\n",
    "        self.trans_probs = trans_probs\n",
    "        self.emission_probs = emission_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_probs_7_state = [0.00, 0.00, 0.00, 1.00, 0.00, 0.00, 0.00]\n",
    "\n",
    "trans_probs_7_state = [\n",
    "    [0.00, 0.00, 0.90, 0.10, 0.00, 0.00, 0.00],\n",
    "    [1.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 1.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.05, 0.90, 0.05, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 1.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.00],\n",
    "    [0.00, 0.00, 0.00, 0.10, 0.90, 0.00, 0.00],\n",
    "]\n",
    "\n",
    "emission_probs_7_state = [\n",
    "    #   A     C     G     T\n",
    "    [0.30, 0.25, 0.25, 0.20],\n",
    "    [0.20, 0.35, 0.15, 0.30],\n",
    "    [0.40, 0.15, 0.20, 0.25],\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.20, 0.40, 0.30, 0.10],\n",
    "    [0.30, 0.20, 0.30, 0.20],\n",
    "    [0.15, 0.30, 0.20, 0.35],\n",
    "]\n",
    "\n",
    "hmm_7_state = hmm(init_probs_7_state, trans_probs_7_state, emission_probs_7_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this time the function `translate_indices_to_path` is a bit different. In the given model the states 0, 1, 2 represent coding (C), state 3 represents non-coding (N) and states 4, 5, 6 represent reverse-coding (R) as explained in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_indices_to_path(indices):\n",
    "    mapping = ['C', 'C', 'C', 'N', 'R', 'R', 'R']\n",
    "    return ''.join([mapping[i] for i in indices])\n",
    "\n",
    "def translate_observations_to_indices(obs):\n",
    "    mapping = {'a': 0, 'c': 1, 'g': 2, 't': 3}\n",
    "    return [mapping[symbol.lower()] for symbol in obs]\n",
    "\n",
    "def translate_indices_to_observations(indices):\n",
    "    mapping = ['a', 'c', 'g', 't']\n",
    "    return ''.join(mapping[idx] for idx in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_table(m, n):\n",
    "    \"\"\"Make a table with `m` rows and `n` columns filled with zeros.\"\"\"\n",
    "    return [[0] * n for _ in range(m)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now insert your Viterbi implementation (log transformed) in the cell below, this means that you should copy `compute_w_log`, `opt_path_prob_log`, `backtrack_log` and any other functions you may have defined yourself for your Viterbi implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021021021021021021021021021021021021021021021021021021021021021021064564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564521021021021021021021021021021021064564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564556456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456452102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102100210210210210210210210210210210210210210210210210210210210210210\n"
     ]
    }
   ],
   "source": [
    "def viterbi_training(K, D, x, z, I):\n",
    "    model = training_by_counting(K, D, x, z)\n",
    "    \n",
    "    for i in range(I):\n",
    "        w = compute_w_log(model, x)\n",
    "        z_vit = backtrack_log(model, x, w)\n",
    "        model = training_by_counting(K, D, x, z_vit)\n",
    "    \n",
    "    return z_vit\n",
    "\n",
    "print(viterbi_training(7, 4, x_long, z_long, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding genes in a genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use your Viterbi implementation to compute an annotation for genome 1 and 2. Save the annotation in a variable (remember to translate the indicies to a path using `translate_indices_to_path`). Feel free to define a function that wraps `compute_w_log` and `backtrack_log` so that you don't have to call both functions each time you want an annotation for a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'true-ann1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Laura\\OneDrive\\Aarhus Universitet\\Molekylær medicin\\7. semester\\Computational thinking\\TØ\\TO-SCRIPTS\\TO13\\ctib-week13-exercises-training-genefinding-e2023.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m translate_indices_to_path(viterbi_training(\u001b[39m7\u001b[39;49m, \u001b[39m4\u001b[39;49m, g1[\u001b[39m'\u001b[39;49m\u001b[39mgenome1\u001b[39;49m\u001b[39m'\u001b[39;49m], z1, \u001b[39m3\u001b[39;49m))\n",
      "\u001b[1;32mc:\\Users\\Laura\\OneDrive\\Aarhus Universitet\\Molekylær medicin\\7. semester\\Computational thinking\\TØ\\TO-SCRIPTS\\TO13\\ctib-week13-exercises-training-genefinding-e2023.ipynb Cell 41\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mviterbi_training\u001b[39m(K, D, x, z, I):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model \u001b[39m=\u001b[39m training_by_counting(K, D, x, z)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(I):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         w \u001b[39m=\u001b[39m compute_w_log(model, x)\n",
      "\u001b[1;32mc:\\Users\\Laura\\OneDrive\\Aarhus Universitet\\Molekylær medicin\\7. semester\\Computational thinking\\TØ\\TO-SCRIPTS\\TO13\\ctib-week13-exercises-training-genefinding-e2023.ipynb Cell 41\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_by_counting\u001b[39m(K, D, x, z):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    Returns a HMM trained on x and z cf. training-by-counting.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     initial_list, transition_list, emission_list \u001b[39m=\u001b[39m count_transitions_and_emissions(K, D, x, z)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(emission_list)): \u001b[39m#rækken\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\Laura\\OneDrive\\Aarhus Universitet\\Molekylær medicin\\7. semester\\Computational thinking\\TØ\\TO-SCRIPTS\\TO13\\ctib-week13-exercises-training-genefinding-e2023.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m initial_list \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m x \u001b[39m=\u001b[39m translate_observations_to_indices(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m z \u001b[39m=\u001b[39m translate_path_to_indices(z)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(K):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     initial_list\u001b[39m.\u001b[39mappend(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Laura\\OneDrive\\Aarhus Universitet\\Molekylær medicin\\7. semester\\Computational thinking\\TØ\\TO-SCRIPTS\\TO13\\ctib-week13-exercises-training-genefinding-e2023.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate_path_to_indices\u001b[39m(path):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mint\u001b[39;49m(x), path))\n",
      "\u001b[1;32mc:\\Users\\Laura\\OneDrive\\Aarhus Universitet\\Molekylær medicin\\7. semester\\Computational thinking\\TØ\\TO-SCRIPTS\\TO13\\ctib-week13-exercises-training-genefinding-e2023.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate_path_to_indices\u001b[39m(path):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Laura/OneDrive/Aarhus%20Universitet/Molekyl%C3%A6r%20medicin/7.%20semester/Computational%20thinking/T%C3%98/TO-SCRIPTS/TO13/ctib-week13-exercises-training-genefinding-e2023.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39;49m(x), path))\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'true-ann1'"
     ]
    }
   ],
   "source": [
    "translate_indices_to_path(viterbi_training(7, 4, g1['genome1'], z1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the predicted annotations to the true annotations. Read the true annotations (`true-ann1.fa` and `true-ann2.fa`) and use the `compute_accuracy` function given below to compare the predicted annotation to the true annotation by computing the accurary. Note that there are other ways to measure the quality of a prediction annotation against the true annotation, e.g. the ACC as shown in the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(true_ann, pred_ann):\n",
    "    if len(true_ann) != len(pred_ann):\n",
    "        return 0.0\n",
    "    return sum(1 if true_ann[i] == pred_ann[i] else 0 \n",
    "               for i in range(len(true_ann))) / len(true_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code to read the annotations and compute the accuracies of your predictions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used the stock `hmm_7_state` for prediction. In a real application, one would train the HMM on genomes with known gene structure in order to make a model that reflects reality. \n",
    "\n",
    "Make a HMM `hmm_7_state_genome1` that has a transition diagram similar to `hmm_7_state`, but where the transition, emission, and initial probabilities are set by training by counting on `genome1.fa` and its corresponding true gene structure as given in `true-ann1.fa`.\n",
    "\n",
    "You should be able to use your implementation of training by counting as done above, but you must translate the annotation in `annotation1.fa` into a proper sequence of hidden states, i.e. the annotation `NCCCNRRRN` would correspond to `321034563`.\n",
    "\n",
    "Use the trained HMM `hmm_7_state_genome1` to predict the gene structure of genome 2, and compare the predicted annotation to true annotation (`true-ann2.fa`). Is the accurracy better than your prediction on genome 2 using `hmm_7_state`?\n",
    "\n",
    "Implement training by counting in the cell below. We'll use it to train a new model for predicting genes. Feel free to define any helper functions you find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to get hmm_7_state_genome1 using trainig by counting, predict an annotation of genome2, and compare the prediction to true-ann2.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the above, where you train on genome 2 and predict on genome 1, i.e. make model `hmm_7_state_genome2` using training by counting on `true-ann2.fa`, predict the gene structure of `genome1.fa` and compare your prediction against `true-ann1.fa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code to get hmm_7_state_genome2 using trainig by counting, predict an annotation of genome1, and compare the prediction to true-ann1.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have time you can redo the above for other training methods, e.g. Viterbi training that you also considered above. I.e. train a model `hmm_7_state_genome1_vit` using Viterbi training on `genome1.fa`, and use it to predict a gene structure for genome 2.\n",
    "\n",
    "You can also experiment with other HMMs that allow for a more precise modelling of gene structure as explained in class, e.g. the model with 31 states that models start- and stop-codons. What is the best accuracy that you can obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
